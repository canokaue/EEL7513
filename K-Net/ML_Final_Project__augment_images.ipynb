{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_Final_Project__augment_images.ipynb","provenance":[],"collapsed_sections":["ti0ixS9zaG3X","yRBLd9LxaKkz"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6dWWLSgMJ0XA","colab_type":"text"},"source":["# Aplicação de CNNs para a classificação multi-label de peças de roupa\n","\n","#### Descrição\n","\n","Projeto final da disciplina [EEL7513-09202|EEL7514-08235|EEL510417-41000056ME/DO (20192) - Introdução ao Aprendizado de Máquina](https://moodle.ufsc.br/course/view.php?id=110125).\n","\n","#### Equipe\n","\n","- Kauê Cano\n","- Ruan Cardoso Comelli"]},{"cell_type":"markdown","metadata":{"id":"HQHA4Pc0Wc2_","colab_type":"text"},"source":["## Inicialização"]},{"cell_type":"code","metadata":{"id":"IxD5oMeSyZ5U","colab_type":"code","colab":{}},"source":["user = 'ruan.comelli@lepten.ufsc.br'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QLo_C717KwaT","colab_type":"code","outputId":"950a2e39-499b-4f2d-df1a-f27c541e7c31","executionInfo":{"status":"ok","timestamp":1575477404034,"user_tz":180,"elapsed":1909,"user":{"displayName":"Pity Comelli","photoUrl":"","userId":"13415078146028656491"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from pathlib import Path\n","\n","from google.colab import drive\n","\n","drive_path = Path('/content/drive')\n","\n","drive.mount(str(drive_path))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4hICJKKXUcBl","colab_type":"code","colab":{}},"source":["if user in {'ruan.comelli@lepten.ufsc.br', 'ruancomelli@gmail.com', 'rugortal@gmail.com'}:\n","    project_path = (\n","        drive_path\n","        / 'My Drive'\n","        / 'Studies'\n","        / '2019.3'\n","        / 'EEL510417 - Tópicos Especiais em Processamento de Sinais - Introdução ao Aprendizado de Máquina'\n","        / 'Final Project'\n","        / 'Codes'\n","    )\n","datasets_path = project_path / 'datasets'\n","deepfashion_path = datasets_path / 'DeepFashion'\n","fashion550k_path = datasets_path / 'Fashion550k'\n","\n","models_path = project_path / 'models'\n","models_path.mkdir(parents=True, exist_ok=True)\n","log_path = project_path / 'log'\n","log_path.mkdir(parents=True, exist_ok=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bLkfs6jKQ9k","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.append(str(project_path)) # this allows us to import modules defined locally"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KCnY01uOZAep","colab_type":"text"},"source":["## Definições"]},{"cell_type":"markdown","metadata":{"id":"ti0ixS9zaG3X","colab_type":"text"},"source":["### Impressão e formatação"]},{"cell_type":"code","metadata":{"id":"408swyB2GnG9","colab_type":"code","colab":{}},"source":["def print_header(\n","    s: str,\n","    level: int = 0, \n","    levels=['=', '-', '~', '*']\n","):\n","    \"\"\"Standardized method for printing a section header.\n","\n","    Prints the argument s underlined.\n","    \n","    Parameters\n","    ----------\n","    s      : string to be printed\n","    level  : index of level symbol to be used\n","    levels : list of level symbols to choose from\n","    \"\"\"\n","    print()\n","    print(s)\n","    print(levels[level] * len(s))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yRBLd9LxaKkz","colab_type":"text"},"source":["### Caminhos"]},{"cell_type":"code","metadata":{"id":"7qYcJljzZRme","colab_type":"code","colab":{}},"source":["def relative_path(origin, destination):\n","    from os.path import relpath\n","    return relpath(destination, start=origin)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bfhqqQ3FaUUX","colab_type":"text"},"source":["### Containers"]},{"cell_type":"code","metadata":{"id":"abJ-UUs1aXob","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","\n","def missing_elements(int_list): # source: adapted from <https://stackoverflow.com/questions/16974047/efficient-way-to-find-missing-elements-in-an-integer-sequence>\n","    int_list = sorted(int_list)\n","    if int_list:\n","        start, end = int_list[0], int_list[-1]\n","        full_list = set(range(start, end + 1))\n","        return sorted(full_list.difference(int_list))\n","    else:\n","        return set([])\n","    \n","def merge_dicts(*dict_args):\n","    \"\"\"\n","    Given any number of dicts, shallow copy and merge into a new dict,\n","    precedence goes to key value pairs in latter dicts.\n","    \"\"\"\n","    result = {}\n","    for dictionary in dict_args:\n","        result.update(dictionary)\n","    return result\n","\n","def extract_value(dicts, key, default_behaviour='value', default=None):\n","    if isinstance(dicts, dict):\n","        dicts = [dicts]\n","    \n","    for d in dicts:\n","        if key in d:\n","            return d[key]\n","        \n","    default_behaviour = default_behaviour.lower()\n","        \n","    if default_behaviour == 'value':\n","        return default\n","    elif default_behaviour == 'raise':\n","        raise ValueError(f'key {key} was not found in the dictionaries.')\n","    else:\n","        raise ValueError(f'default_behaviour must be either \\'value\\' or \\'raise\\'. Got \\'{default_behaviour}\\'.')\n","\n","def extract_values(dicts, keys, default_behaviour='value', default=None):\n","    if isinstance(dicts, dict):\n","        dicts = [dicts]\n","    \n","    return {\n","        key: extract_value(dicts, key, default_behaviour='value', default=default)\n","        for key in keys\n","    }"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5HTGerDmWvI8","colab_type":"text"},"source":["## Configuração"]},{"cell_type":"code","metadata":{"id":"Chj59fhB-2uV","colab_type":"code","colab":{}},"source":["DATA_FORMAT = 'channels_last'\n","IMG_SIZE = (224, 224)\n","IMG_SHAPE = (\n","    IMG_SIZE + (3,)\n","    if DATA_FORMAT == 'channels_last'\n","    else (3,) + IMG_SIZE\n",")\n","BATCH_SIZE = 128\n","RESCALE = 1./255\n","FILL_MODE = 'nearest'\n","\n","validate_filenames = True\n","\n","augment_previously = True\n","fill_aug_imgs = True"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"obb5i2jY8bSt","colab_type":"text"},"source":["# DeepFashion"]},{"cell_type":"markdown","metadata":{"id":"9qRKbCo5JWLF","colab_type":"text"},"source":["## Preparação"]},{"cell_type":"markdown","metadata":{"id":"IBx9nEDHYtmm","colab_type":"text"},"source":["### Importar dados"]},{"cell_type":"code","metadata":{"id":"MAUasLxq8ZaH","colab_type":"code","outputId":"59bd8364-7e0e-49a7-f33a-742ed12f4754","executionInfo":{"status":"ok","timestamp":1575477404043,"user_tz":180,"elapsed":1845,"user":{"displayName":"Pity Comelli","photoUrl":"","userId":"13415078146028656491"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from sklearn.preprocessing import MultiLabelBinarizer\n","\n","category_attribute_prediction_path = (deepfashion_path / 'Category and Attribute Prediction Benchmark').absolute().resolve()\n","images_path = (category_attribute_prediction_path / 'Img').absolute().resolve()\n","augmented_imgs_path = (category_attribute_prediction_path / 'Img' / 'aug_img').absolute().resolve()\n","annotations_path = (category_attribute_prediction_path / 'Anno').absolute().resolve()\n","evaluation_path = (category_attribute_prediction_path / 'Eval').absolute().resolve()\n","\n","dataset_anno_path = annotations_path / 'dataset.csv'\n","dataset_path = (category_attribute_prediction_path / 'Img' / 'dataset').absolute().resolve()\n","dataset_path.mkdir(parents=True, exist_ok=True)\n","\n","# n_categories = int(pd.read_csv(annotations_path / 'list_category_cloth.txt', nrows=1, header=None)[0][0])\n","# categories = pd.read_csv(annotations_path / 'list_category_cloth.txt', skiprows=1, delimiter=r\"\\s\\s+\", engine='python')\n","# categories = categories.astype({\n","#     'category_name': str,\n","#     'category_type': int\n","# })\n","# category_types = {\n","#     1: 'upper-body clothes',\n","#     2: 'lower-body clothes',\n","#     3: 'full-body clothes'\n","# }\n","\n","# n_category_imgs = int(pd.read_csv(annotations_path / 'list_category_img.txt', nrows=1, header=None)[0][0])\n","# category_imgs = pd.read_csv(annotations_path / 'list_category_img.txt', skiprows=1, delim_whitespace=True)\n","# category_imgs = category_imgs.astype({\n","#     'image_name': str,\n","#     'category_label': int\n","# })\n","\n","n_attributes = int(pd.read_csv(annotations_path / 'list_attr_cloth.txt', nrows=1, header=None)[0][0])\n","attributes = pd.read_csv(annotations_path / 'list_attr_cloth.txt', skiprows=1, delimiter=r\"\\s\\s+\", engine='python')\n","attributes = attributes.astype({\n","    'attribute_name': str,\n","    'attribute_type': int\n","})\n","attribute_types = {\n","    1: 'texture-related attributes',\n","    2: 'fabric-related attributes',\n","    3: 'shape-related attributes',\n","    4: 'part-related attributes',\n","    5: 'style-related attributes'\n","}\n","\n","attr_binarizer = MultiLabelBinarizer()\n","attr_binarizer.fit([attributes['attribute_name']])\n","n_labels = attr_binarizer.classes_.size\n","print(n_labels, 'classes found:', attr_binarizer.classes_)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["1000 classes found: ['a-line' 'abstract' 'abstract chevron' 'abstract chevron print'\n"," 'abstract diamond' 'abstract floral' 'abstract floral print'\n"," 'abstract geo' 'abstract geo print' 'abstract paisley' 'abstract pattern'\n"," 'abstract print' 'abstract printed' 'abstract stripe' 'acid' 'acid wash'\n"," 'americana' 'angeles' 'animal' 'animal print' 'ankle' 'applique'\n"," 'arrow collar' 'art' 'asymmetric' 'asymmetrical' 'asymmetrical hem'\n"," 'athletic' 'audrey' 'babe' 'babydoll' 'back bow' 'back cutout'\n"," 'back knit' 'back lace' 'back striped' 'backless' 'baja' 'bandage'\n"," 'bandana' 'bandana print' 'barbie' 'baroque' 'baroque print' 'baseball'\n"," 'basic' 'basquiat' 'batwing' 'beach' 'bead' 'beaded' 'beaded chiffon'\n"," 'beaded collar' 'beaded sheer' 'beaded shift' 'beatles' 'bed' 'bejeweled'\n"," 'bell' 'bell-sleeve' 'bella' 'belted' 'belted chiffon' 'belted floral'\n"," 'belted floral print' 'belted lace' 'belted maxi' 'belted plaid'\n"," 'bermuda' 'bib' 'big' 'bike' 'biker' 'bird' 'bird print' 'blah' 'bleach'\n"," 'bleached' 'bleached denim' 'blurred' 'boat neck' 'bodycon'\n"," 'bodycon midi' 'boho' 'bold' 'botanical' 'botanical print' 'bow'\n"," 'bow-back' 'bow-front' 'box' 'box pleat' 'box-pleated' 'boxy' 'boxy crop'\n"," 'boxy knit' 'boxy lace' 'boxy pocket' 'boxy striped' 'boyfriend'\n"," 'braided' 'breton' 'breton stripe' 'brocade' 'brooklyn' 'brooklyn nets'\n"," 'brushstroke' 'brushstroke print' 'burnout' 'bustier' 'butterfly'\n"," 'butterfly print' 'button' 'button-front' 'buttoned' 'cable' 'cable knit'\n"," 'cable-knit' 'caged' 'california' 'camera' 'cami' 'cami crop' 'cami maxi'\n"," 'camo' 'camouflage' 'candy' 'canvas' 'cap-sleeve' 'capri' 'cardio'\n"," 'cargo' 'cat' 'chambray' 'chambray drawstring' 'checked' 'checkered'\n"," 'cheetah' 'chenille' 'chevron' 'chevron print' 'chic' 'chiffon'\n"," 'chiffon floral' 'chiffon lace' 'chiffon layered' 'chiffon maxi'\n"," 'chiffon paneled' 'chiffon pleated' 'chiffon shift' 'chiffon shirt'\n"," 'chiffon surplice' 'chiffon-paneled' 'chino' 'chunky' 'chunky knit'\n"," 'cinched' 'circle' 'cities' 'city' 'civil' 'clashist' 'classic'\n"," 'classic cotton' 'classic crew' 'classic crew neck' 'classic denim'\n"," 'classic fit' 'classic knit' 'classic pocket' 'classic skinny'\n"," 'classic striped' 'classic v-neck' 'classic woven' 'clean' 'clean wash'\n"," 'cloud' 'cloud wash' 'coast' 'coated' 'coffee' 'collar' 'collar lace'\n"," 'collared' 'collarless' 'collarless faux' 'colorblock'\n"," 'colorblock pocket' 'colorblocked' 'combo' 'combo maxi' 'contrast'\n"," 'contrast trim' 'contrast-trimmed' 'convertible' 'corduroy' 'cotton'\n"," 'cotton drawstring' 'cotton knit' 'cotton-blend' 'cover-up' 'cowl'\n"," 'cowl neck' 'cozy' 'crepe' 'crepe shift' 'crepe woven' 'crew' 'crew neck'\n"," 'crinkled' 'crisscross' 'crisscross-back' 'crochet' 'crochet crop'\n"," 'crochet embroidered' 'crochet floral' 'crochet fringe' 'crochet knit'\n"," 'crochet lace' 'crochet maxi' 'crochet mesh' 'crochet overlay'\n"," 'crochet-paneled' 'crochet-trimmed' 'crocheted' 'crocheted lace' 'crop'\n"," 'cropped' 'cropped knit' 'cross-back' 'crossback' 'cuffed' 'cuffed denim'\n"," 'cuffed-sleeve' 'curved' 'curved hem' 'cut' 'cute' 'cutoff' 'cutout'\n"," 'cutout lace' 'cutout maxi' 'cutout sheath' 'cutout-back' 'dainty'\n"," 'daisy' 'daisy print' 'damask' 'daring' 'dark' 'darling' 'deep v-neck'\n"," 'deep-v' 'defyant' 'denim' 'denim drawstring' 'denim pencil'\n"," 'denim shift' 'denim shirt' 'denim skater' 'denim utility' 'desert'\n"," 'destroyed' 'devil' 'diamond' 'diamond print' 'dip-dye' 'dip-dyed'\n"," 'distressed' 'distressed low-rise' 'distressed mid-rise'\n"," 'distressed skinny' 'ditsy' 'ditsy floral' 'ditsy floral print' 'doll'\n"," 'dolman' 'dolman sleeve' 'dolman-sleeve' 'dolphin' 'dolphin hem' 'doodle'\n"," 'dot' 'dots' 'dotted' 'double-breasted' 'drape-front' 'draped'\n"," 'draped open-front' 'draped shawl' 'draped surplice' 'drapey'\n"," 'drawstring' 'dream' 'dreamcatcher' 'dreamer' 'drop waist' 'drop-sleeve'\n"," 'drop-waist' 'dropped' 'dye' 'dynamite' 'eagle' 'edge' 'eiffel'\n"," 'elasticized' 'elegant' 'elephant' 'elephant print' 'embellished'\n"," 'embroidered' 'embroidered fit' 'embroidered floral' 'embroidered gauze'\n"," 'embroidered gauze peasant' 'embroidered lace' 'embroidered maxi'\n"," 'embroidered mesh' 'embroidered peasant' 'embroidered shift'\n"," 'embroidered woven' 'embroidery' 'enchanted' 'ethereal' 'everyday'\n"," 'eyelash' 'eyelash knit' 'eyelash lace' 'eyelet' 'eyelet fit' 'faded'\n"," 'fair' 'fair isle' 'fan' 'fancy' 'faux' 'faux fur' 'faux leather'\n"," 'faux leather mini' 'faux leather moto' 'faux leather paneled'\n"," 'faux leather pencil' 'faux leather skater' 'faux leather varsity'\n"," 'faux leather-paneled' 'faux leather-trimmed' 'faux shearling'\n"," 'faux suede' 'faux-wrap' 'feather' 'festive' 'field' 'fisherman' 'fit'\n"," 'fit flare' 'fit skinny' 'fitted' 'fitted v-neck' 'flare' 'flared' 'flat'\n"," 'flat front' 'flat-front' 'flawless' 'flirty' 'floral' 'floral flutter'\n"," 'floral knit' 'floral lace' 'floral lace mini' 'floral lace sheath'\n"," 'floral lace skater' 'floral maxi' 'floral mesh' 'floral midi'\n"," 'floral mini' 'floral paisley' 'floral pattern' 'floral peasant'\n"," 'floral pleated' 'floral print' 'floral print skater'\n"," 'floral print strapless' 'floral print surplice' 'floral shift'\n"," 'floral skater' 'floral surplice' 'floral textured' 'floral-embroidered'\n"," 'flounce' 'flounce maxi' 'flounced' 'flower' 'flowy' 'floyd' 'fluted'\n"," 'flutter' 'flutter sleeve' 'flutter-sleeve' 'foil' 'fold-over' 'foldover'\n"," 'folk' 'folk print' 'foulard' 'fox' 'france' 'frayed' 'free spirit'\n"," 'french' 'french terry' 'fresh' 'frida' 'fringe' 'fringed' 'fur' 'fuzzy'\n"," 'fuzzy knit' 'galaxy' 'garden' 'garden party' 'gathered waistline'\n"," 'gaucho' 'gauze' 'gauze maxi' 'gauze peasant' 'gauzy' 'gem' 'genuine'\n"," 'geo' 'geo pattern' 'geo print' 'geo stripe' 'georgette' 'gingham'\n"," 'giraffe' 'giraffe print' 'girl' 'girls' 'glass' 'glitter' 'graphic'\n"," 'graphic muscle' 'graphic racerback' 'grid' 'grid print' 'grunge' 'guns'\n"," 'halen' 'harem' 'heart' 'heart print' 'heat' 'heathered' 'heathered knit'\n"," 'heathered stripe' 'heathered v-neck' 'hem' 'hepburn' 'heroes'\n"," 'herringbone' 'high-low' 'high-neck' 'high-rise' 'high-rise skinny'\n"," 'high-slit' 'high-slit maxi' 'high-waist' 'high-waisted' 'hood' 'hooded'\n"," 'hooded maxi' 'hooded utility' 'houndstooth' 'ikat' 'ikat print'\n"," 'illusion' 'illusion neckline' 'inset' 'internet' 'island' 'isle'\n"," 'jacquard' 'joie' 'kahlo' 'kaleidoscope' 'kaleidoscope print' 'kangaroo'\n"," 'kangaroo pocket' 'keyhole' 'kid' 'killin' 'kiss' 'kitty' 'knee-length'\n"," 'knit' 'knit lace' 'knit longline' 'knit maxi' 'knit mini' 'knit open'\n"," 'knit pencil' 'knit pocket' 'knit raglan' 'knit shawl' 'knit skater'\n"," 'knit stripe' 'knit striped' 'knit trapeze' 'knit v-neck' 'knotted'\n"," 'kurt' 'la' 'lace' 'lace layered' 'lace maxi' 'lace mesh' 'lace midi'\n"," 'lace mini' 'lace overlay' 'lace panel' 'lace paneled' 'lace pencil'\n"," 'lace peplum' 'lace pleated' 'lace print' 'lace sheath' 'lace sheer'\n"," 'lace shift' 'lace skater' 'lace sleeve' 'lace trim' 'lace-paneled'\n"," 'lace-trim' 'lace-trimmed' 'lace-up' 'lacy' 'ladder-back' 'lady' 'lakers'\n"," 'lapel' 'laser' 'lattice' 'layered' 'leaf' 'leaf print' 'leather'\n"," 'leather mini' 'leather moto' 'leather paneled' 'leather pencil'\n"," 'leather peplum' 'leather quilted' 'leather skater' 'leather trimmed'\n"," 'leather varsity' 'leather-paneled' 'leather-trimmed' 'leave' 'led'\n"," 'leopard' 'leopard print' 'life' 'light' 'lightning' 'linen'\n"," 'linen-blend' 'logo' 'long sleeve' 'long-sleeve' 'long-sleeved'\n"," 'longline' 'longline shirt' 'loop' 'loose' 'loose-knit' 'lounge' 'love'\n"," 'lover' 'low-rise' 'low-rise skinny' 'loyal' 'luxe' 'm-slit'\n"," 'm-slit maxi' 'mandala' 'mandala print' 'mandarin' 'map' 'marble'\n"," 'marble print' 'marilyn' 'marilyn monroe' 'marled' 'marled stripe'\n"," 'matelot' 'maxi' 'medallion' 'medallion print' 'medium' 'meow' 'mesh'\n"," 'mesh overlay' 'mesh panel' 'mesh paneled' 'mesh racerback'\n"," 'mesh-paneled' 'mesh-trimmed' 'metallic' 'miami' 'mickey' 'mickey mouse'\n"," 'mid rise' 'mid rise skinny' 'mid-rise' 'mid-rise skinny' 'midi' 'mina'\n"," 'mineral' 'mineral wash' 'mini' 'minnie' 'minnie mouse' 'mirrored'\n"," 'mixed' 'mixed print' 'mixed stripe' 'mob' 'mock' 'mock neck' 'mock-neck'\n"," 'mod' 'modernist' 'monroe' 'moon' 'morning' 'mosaic' 'mosaic print'\n"," 'moto' 'multi-stripe' 'muscle' 'muse' 'nautical' 'nautical stripe'\n"," 'nautical striped' 'neck ribbed' 'neck skater' 'neck striped' 'neckline'\n"," 'neon' 'neoprene' 'nets' 'netted' 'new york' 'night' 'notched collar'\n"," 'notorious' 'ny' 'nyc' 'nylon' 'off-the-shoulder' 'oil' 'ombre'\n"," 'one-button' 'one-shoulder' 'open-back' 'open-front' 'open-knit'\n"," 'open-shoulder' 'organza' 'origami' 'ornate' 'ornate paisley'\n"," 'ornate print' 'overlay' 'overlay sheath' 'oversized' 'oxford' 'paint'\n"," 'paint splatter' 'painted' 'paisley' 'paisley print' 'palm' 'palm print'\n"," 'palm springs' 'palm tree' 'pan' 'panel' 'paneled' 'paradise' 'paris'\n"," 'party' 'patched' 'patchwork' 'pattern' 'patterned' 'peasant' 'pencil'\n"," 'peplum' 'perforated' 'performance' 'pima' 'pin' 'pineapple' 'pink'\n"," 'pinstripe' 'pinstriped' 'pintuck' 'pintuck pleated' 'pintucked' 'pizza'\n"," 'pj' 'plaid' 'plaid shirt' 'please' 'pleat' 'pleated' 'pleated skater'\n"," 'pleated woven' 'pocket' 'pointelle' 'polka dot' 'polo' 'pom-pom' 'ponte'\n"," 'popcorn' 'popover' 'posh' 'power' 'print' 'print racerback'\n"," 'print satin' 'print scuba' 'print shift' 'print shirt' 'print skater'\n"," 'print smock' 'print smocked' 'print strapless' 'print strappy'\n"," 'print surplice' 'print tulip' 'print v-neck' 'print woven' 'printed'\n"," 'puffer' 'pullover' 'purl' 'quilted' 'quirky' 'racerback' 'rad' 'raga'\n"," 'raglan' 'raglan sleeve' 'rainbow' 'raw' 'raw-cut' 'rebel' 'red'\n"," 'refined' 'regime' 'relaxed' 'retro' 'reverse' 'reversible' 'rhinestone'\n"," 'rib' 'rib-knit' 'ribbed' 'ribbed stripe' 'ribbed-knit' 'ringer' 'ripped'\n"," 'rise' 'rise skinny' 'roll' 'rolling' 'rolling stones' 'roman' 'rose'\n"," 'rose skater' 'roses' 'round' 'ruched' 'ruffle' 'ruffle trim' 'ruffled'\n"," 'rugby' 'rugby stripe' 'rugby striped' 'run' 'running' 'rustic' 'safari'\n"," 'sateen' 'satin' 'scallop' 'scalloped' 'scoop' 'scoop-neck' 'scuba'\n"," 'scuba skater' 'sea' 'seam' 'seamless' 'seaside' 'seersucker' 'self-tie'\n"," 'semi-sheer' 'sequin' 'sequined' 'shaggy' 'shark' 'shawl' 'shearling'\n"," 'sheath' 'sheer' 'sheer-paneled' 'shift' 'shirred' 'shirt' 'shopping'\n"," 'shore' 'shoulder' 'shredded' 'side slit' 'side-slit' 'single-button'\n"," 'skater' 'skinny' 'skinny stretch' 'skort' 'sky' 'sleek' 'sleeve'\n"," 'sleeveless' 'slick' 'slim' 'slip' 'slit' 'slouchy' 'slub' 'slub-knit'\n"," 'smart' 'smile' 'smock' 'smocked' 'snap' 'snoopy' 'soft' 'solid'\n"," 'sophisticated' 'southwestern' 'southwestern-inspired'\n"," 'southwestern-patterned' 'southwestern-print' 'sparkling' 'speckled'\n"," 'spirit' 'splatter' 'split' 'split-back' 'split-neck' 'spongebob'\n"," 'sporty' 'spotted' 'springs' 'square' 'standout' 'star' 'stars' 'stone'\n"," 'stone washed' 'stones' 'straight-leg' 'strap' 'strapless'\n"," 'strapless tribal' 'strappy' 'stretch' 'stretch-knit' 'stripe' 'striped'\n"," 'striped trapeze' 'striped v-neck' 'stripes' 'structured' 'studded'\n"," 'studio' 'suede' 'summer' 'sun' 'sunburst' 'sunflower' 'surfer'\n"," 'surplice' 'suspender' 'sweet' 'sweetheart' 'swim' 'swing' 'swiss'\n"," 't-back' 'taco' 'tapestry' 'tartan' 'tasmanian' 'tassel' 'tasseled'\n"," 'terry' 'texas' 'textured' 'textured woven' 'thermal' 'tie-back'\n"," 'tie-dye' 'tie-front' 'tie-neck' 'tiered' 'tile' 'toggle' 'tokyo' 'tonal'\n"," 'topstitched' 'tower' 'track' 'training' 'trapeze' 'tree' 'trench'\n"," 'triangle' 'tribal' 'tribal-inspired' 'trim' 'trimmed' 'tropical'\n"," 'trouble' 'trouser' 'tube' 'tulip' 'tulip-back' 'tulle' 'tunic' 'tupac'\n"," 'turtle-neck' 'tweed' 'twill' 'twist-front' 'twisted' 'two-button'\n"," 'two-tone' 'utility' 'v-back' 'v-cut' 'v-neck' 'van' 'varsity'\n"," 'varsity-striped' 'velvet' 'velveteen' 'venice' 'vent' 'vented hem'\n"," 'vertical' 'voyager' 'waffle' 'wake' 'wash' 'washed' 'watercolor' 'wave'\n"," 'weekend' 'west' 'wide-leg' 'wifey' 'wild' 'wildflower' 'windbreaker'\n"," 'windowpane' 'woke' 'workout' 'woven' 'wrap' 'y-back' 'yoga' 'yoke'\n"," 'york' 'youth' 'zeppelin' 'zig' 'zigzag' 'zip' 'zip-front' 'zip-pocket'\n"," 'zip-up' 'zipped' 'zipper' 'zippered']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wsy3nYQ5YxFo","colab_type":"text"},"source":["### Data augmentation"]},{"cell_type":"code","metadata":{"id":"0eHygqCXsGe2","colab_type":"code","outputId":"96dfa6b3-2727-48df-a68f-69ee9fe3c211","executionInfo":{"status":"ok","timestamp":1575393208463,"user_tz":180,"elapsed":70210,"user":{"displayName":"Ruan Cardoso Comelli","photoUrl":"","userId":"11238357870096255104"}},"colab":{"base_uri":"https://localhost:8080/","height":114}},"source":["from ast import literal_eval\n","from tensorflow.keras.preprocessing.image import save_img\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","n_attribute_imgs = int(pd.read_csv(annotations_path / 'list_attr_img.txt', nrows=1, header=None)[0][0])\n","column_names = pd.read_csv(annotations_path / 'list_attr_img.txt', skiprows=1, nrows=1, delim_whitespace=True, header=None).values[0]\n","\n","previously_augmented = False\n","if augment_previously:\n","    attribute_aug_imgs_path = annotations_path / 'attribute_aug_imgs.txt'\n","    try:\n","        print('Trying to read augmented image attributes', end='')\n","        attribute_aug_imgs = pd.read_csv(attribute_aug_imgs_path)\n","        attribute_aug_imgs[column_names[1]] = attribute_aug_imgs[column_names[1]].apply(lambda x: list(y for y in literal_eval(x)))\n","\n","        attribute_aug_imgs = attribute_aug_imgs.astype({\n","            column_names[0]: str,\n","            column_names[1]: object\n","        })\n","\n","        print(' - Done')\n","    except (FileNotFoundError, pd.errors.EmptyDataError):\n","        print(' - File not found... augmenting images later')\n","        attribute_aug_imgs = pd.DataFrame(columns=column_names)\n","        attribute_aug_imgs.to_csv(attribute_aug_imgs_path, index=False)\n","\n","    n_attribute_aug_imgs = len(attribute_aug_imgs.index)\n","    if fill_aug_imgs:\n","        previously_augmented = (n_attribute_aug_imgs == n_attribute_imgs)\n","    else:\n","        previously_augmented = True\n","\n","if not augment_previously or not previously_augmented:\n","    attribute_imgs_path = annotations_path / 'attribute_imgs.txt'\n","    try:\n","        print('Trying to read image attributes', end='')\n","        attribute_imgs = pd.read_csv(attribute_imgs_path)\n","        attribute_imgs[column_names[1]] = attribute_imgs[column_names[1]].apply(lambda x: list(y for y in literal_eval(x)))\n","        print(' - Done')\n","    except (FileNotFoundError, pd.errors.EmptyDataError):\n","        print(' - File not found... reading in chunks from bigger file')\n","        first_row = pd.read_csv(annotations_path / 'list_attr_img.txt', skiprows=2, nrows=1, delim_whitespace=True, header=None).values[0]\n","        attribute_imgs = pd.DataFrame(columns=column_names)\n","        for i, chunk in enumerate(pd.read_csv(\n","                annotations_path / 'list_attr_img.txt',\n","                skiprows=2,\n","                delim_whitespace=True,\n","                header=None,\n","                chunksize=50000,\n","                converters={\n","                    col: lambda x: True if x == '1' else False if x == '-1' else x\n","                    for col in range(1, len(first_row))\n","                }\n","        )):\n","            print(f'Reading chunk #{i}', end='')\n","\n","            chunk = list(chunk.itertuples())\n","            y_values = [\n","                list(\n","                    idx\n","                    for idx, value in enumerate(row[2:])\n","                    if value\n","                ) for row in chunk\n","            ]\n","            chunk = pd.DataFrame({\n","                column_names[0]: [images_path / row[1] for row in chunk],\n","                column_names[1]: [[attributes['attribute_name'][y_] for y_ in y_value] if y_value else ['none'] for y_value in y_values]\n","            }, index=[row[0] for row in chunk])\n","\n","            attribute_imgs = attribute_imgs.append(chunk, verify_integrity=True, sort=False)\n","\n","            print(f' - Done')\n","        try:\n","            print('Trying to write attribute images', end='')\n","            attribute_imgs.to_csv(attribute_imgs_path, index=False)\n","            print(' - Done')\n","        except PermissionError:\n","            print(' - Permission denied')\n","\n","    attribute_imgs = attribute_imgs.astype({\n","        column_names[0]: str,\n","        column_names[1]: object\n","    })\n","\n","expanded_attr_binarizer = MultiLabelBinarizer()\n","if not augment_previously or not previously_augmented:\n","    expanded_attr_binarizer.fit(attribute_imgs[column_names[1]])\n","else:\n","    expanded_attr_binarizer.fit(attribute_aug_imgs[column_names[1]])\n","\n","if augment_previously and not previously_augmented:\n","    print('Augmenting images')\n","\n","    image_data_generator = ImageDataGenerator(\n","        rescale=RESCALE,\n","        data_format=DATA_FORMAT,\n","        fill_mode=FILL_MODE,\n","    )\n","    augmented_imgs_path.mkdir(parents=True, exist_ok=True)\n","\n","    dataframe_iterator = image_data_generator.flow_from_dataframe(\n","        attribute_imgs[n_attribute_aug_imgs:],\n","        x_col=column_names[0],\n","        y_col=column_names[1],\n","        color_mode='rgb',\n","        classes=list(expanded_attr_binarizer.classes_),\n","        class_mode='categorical',\n","        validate_filenames=validate_filenames,\n","        shuffle=False,\n","        target_size=IMG_SIZE,\n","        batch_size=BATCH_SIZE\n","    )\n","    counter = n_attribute_aug_imgs\n","    break_all = False\n","    for batch in dataframe_iterator:\n","        print_header(f'Batch {dataframe_iterator.batch_index}')\n","        for idx, (X, y) in enumerate(zip(*batch)):\n","            y = np.expand_dims(y, axis=0)\n","            inv_y = expanded_attr_binarizer.inverse_transform(y)\n","            \n","            origin = Path(dataframe_iterator.filenames[idx])\n","            file_path = augmented_imgs_path / origin.parts[-2] / origin.parts[-1]\n","            \n","            print(f'Index = {counter}/{n_attribute_imgs} [#{idx} from batch {dataframe_iterator.batch_index}]')\n","            print(f'Origin = {origin}')\n","            print(f'y = {inv_y} [path = {file_path}]')\n","\n","            file_path.parent.mkdir(parents=True, exist_ok=True)\n","            if not file_path.exists():\n","                save_img(file_path, X)\n","            attribute_aug_imgs = attribute_aug_imgs.append({\n","                column_names[0]: str(file_path),\n","                column_names[1]: inv_y[0]\n","            }, ignore_index=True)\n","\n","            counter += 1\n","            if counter == n_attribute_imgs:\n","                break_all = True\n","                break\n","\n","        attribute_aug_imgs.to_csv(attribute_aug_imgs_path, index=False)\n","        if break_all:\n","            break\n","\n","    previously_augmented = True\n","    print('Done')"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Trying to read augmented image attributes - Done\n","Trying to read image attributes - Done\n","Augmenting images\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y9vhyej9H7o7","colab_type":"text"},"source":["### Informação"]},{"cell_type":"code","metadata":{"id":"Qt-aJA_any-h","colab_type":"code","colab":{}},"source":["# print_header('Categories')\n","# print(f'n_categories = {n_categories}')\n","# categories.info()\n","# categories.head()\n","# print('Category types:', category_types)\n","\n","# print_header('Category images')\n","# print(f'n_category_imgs = {n_category_imgs}')\n","# category_imgs.info()\n","# category_imgs.head()\n","\n","print_header('Attributes')\n","print(f'n_attributes = {n_attributes}')\n","attributes.info()\n","attributes.head()\n","print('Category types:', attribute_types)\n","\n","if not augment_previously or not previously_augmented:\n","    print_header('Attribute images')\n","    print(f'n_attribute_imgs = {n_attribute_imgs}')\n","    attribute_imgs.info()\n","    attribute_imgs.head()\n","\n","if previously_augmented:\n","    print_header('Augmented Attribute images')\n","    print(f'n_attribute_imgs = {n_attribute_imgs}')\n","    attribute_aug_imgs.info()\n","    attribute_aug_imgs.head()"],"execution_count":0,"outputs":[]}]}